{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing csv files.\n",
    "crimes_19 = pd.read_csv('input_data/Chicago_Crimes_2019.csv')\n",
    "crimes_20 = pd.read_csv('input_data/Chicago_Crimes_2020.csv')\n",
    "crimes_21 = pd.read_csv('input_data/Chicago_Crimes_2021.csv')\n",
    "fbi_code = pd.read_csv('input_data/FBI_Code.csv', encoding = \"ISO-8859-1\")\n",
    "#fbi_code = pd.read_csv('input_data/FBI_Code.csv',  encoding= 'unicode_escape')\n",
    "iucr_code = pd.read_csv('input_data/IUCR_Codes.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging crimes data for the last 3 years into a signle dataframe\n",
    "crimes_data = pd.merge((pd.merge(crimes_19,crimes_20, how=\"outer\")),crimes_21,how=\"outer\")\n",
    "\n",
    "print(len(crimes_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rafael"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the FBI cvs file\n",
    "df = fbi_code\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the IUCS cvs file\n",
    "df2 = iucr_code\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "df = df.drop(df.columns[[2,3]], axis=1)\n",
    "df.columns=['code', 'description']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "df2 = df2.drop(df2.columns[[3,4]], axis=1)\n",
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and Removing duplicates rows\n",
    "df = df.drop_duplicates()\n",
    "df.head()\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#df.to_csv(r'./Output_data/FBI_code.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and Removing duplicates rows\n",
    "df2 = df2.drop_duplicates()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Columns\n",
    "df2 = df2.rename(columns=({'PRIMARY DESCRIPTION':'PRIMARY_DESCRIPTION','SECONDARY DESCRIPTION':'SECONDARY_DESCRIPTION'}))\n",
    "df2.head()\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#df2.to_csv(r'./Output_data/ICUS_code.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Artem\n",
    "# merging crimes data for the last 3 years into a signle dataframe\n",
    "crimes_data = pd.merge((pd.merge(crimes_19,crimes_20, how=\"outer\")),crimes_21,how=\"outer\")\n",
    "\n",
    "#dropping unnecessary columns\n",
    "crimes_data = crimes_data.drop(columns=['Latitude','Location','Longitude','X Coordinate','Y Coordinate','Updated On'])\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# removing duplicate values\n",
    "crimes_data = crimes_data.drop_duplicates()\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# removing missing values\n",
    "crimes_data = crimes_data.dropna()\n",
    "# crimes_data.shape[0]\n",
    "\n",
    "# Creating a function which will remove extra leading and tailing whitespace from the data.\n",
    "def whitespace_remover(crimes_data):\n",
    "   \n",
    "    # iterating over the columns\n",
    "    for i in crimes_data.columns:\n",
    "         \n",
    "        # checking datatype of each columns\n",
    "        if crimes_data[i].dtype == 'object':\n",
    "             \n",
    "            # applying strip function on column\n",
    "            crimes_data[i] = crimes_data[i].map(str.strip)\n",
    "        else:\n",
    "             \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "        \n",
    "# applyting whitespace_remover function on dataframe        \n",
    "whitespace_remover(crimes_data)\n",
    "\n",
    "#Rename Columns\n",
    "crimes_data = crimes_data.rename(columns=({'Case Number':'Case_Number',\n",
    "                                           'Location Description':'Location_Description',\n",
    "                                           'Community Area':'Community_Area',\n",
    "                                          'FBI Code':'FBI_Code'}))\n",
    "\n",
    "\n",
    "#writting csv file for import into pgadmin data base\n",
    "#crimes_data.to_csv(r'./Output_data/crimes_data.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create database connection\n",
    "connection_string = \"postgres:postgressql@localhost:5432/new_crime_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')\n",
    "# Confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to lower case \n",
    "df2.rename(columns={'IUCR':'iucr','PRIMARY_DESCRIPTION':'primary_description','SECONDARY_DESCRIPTION':'secondary_description' }, inplace=True)\n",
    "crimes_data.columns=['id', 'case_number', 'date', 'block', 'iucr','location_description',\n",
    "                     'arrest', 'domestic','beat','district', 'district_name', 'district_population',\n",
    "                     'ward', 'community_area', 'fbi_code'\n",
    "                    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe into database\n",
    "\n",
    "df2.to_sql(name='iucr_codes', con=engine, if_exists='append', index=False)\n",
    "df.to_sql(name='fbi_description', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_data.to_sql(name='crime_table', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PythonData38]",
   "language": "python",
   "name": "conda-env-.conda-PythonData38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
